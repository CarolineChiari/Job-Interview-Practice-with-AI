{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Interview Wihth OpenAI's GPT model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you need to get started\n",
    "\n",
    "This notebook needs a `.env` file in the same folder with the following data:\n",
    "```\n",
    "SPEECH_KEY=<Cognitive services key>\n",
    "SPEECH_REGION=<cognitive service region>\n",
    "SPEECH_LANGUAGE=<cognitive services language>\n",
    "OPENAI_KEY=<openAI API key>\n",
    "```\n",
    "\n",
    "## How do I get the speech key and region?\n",
    "\n",
    "You need a valid [Azure](https://portal.azure.com/) subscription in order to get those keys.\n",
    "\n",
    "Once you do, follow these steps:\n",
    "- (optional) Create a new Azure Resource Group and call it `speech`\n",
    "- From the resource group, click on **Create** and search for `Cognitive  Services`\n",
    "- Select the first one anc click **Create**\n",
    "- Choose your subscription and resource group. Also provide a name and choose the pricing tier. You can find more information about Cognitive services' pricing [here](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/)\n",
    "- Leave everything else as default and click **Review + Create** then click **Create** if there are no issues.\n",
    "- Once the service is created, either click on **Go to Resource** or navigate to your resource\n",
    "- Click on **Keys and Endpoint** on the left pane\n",
    "- From there you can copy your key and region, and paste it in the `.env` file mentioned above.\n",
    "\n",
    "## How do I get the OpenAI Key?\n",
    "\n",
    "You need a valid paid subscription to OpenAI. More information about costs [here](https://openai.com/api/pricing/)\n",
    "\n",
    "- Go to [OpenAI's API website](https://openai.com/api/)\n",
    "- **Log In** or **Sign Up** if you haven't done so already\n",
    "- Click on your profile in the right hand side of the screen\n",
    "- Click on **View API Keys**\n",
    "- Click on **Create New Secret Key**\n",
    "- Copy and paste the value in the `.env` file mentioned above.\n",
    "\n",
    "## How to use this notebook?\n",
    "\n",
    "In the code box below, replace the `jobTitle` with the job title you want to practice with.\n",
    "Enter the `numberOfQuestions` you want to practice on.\n",
    "\n",
    "Run all the cells.\n",
    "\n",
    "When the AI asks you a question, there will be a shot tone to indicate that it's ready to listen to you. If you stop talking for 2.5s, it will automatically assume you are done answering and move to the next question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the interview parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobTitle = \"Random\" # If you enter 'Random' as the job title, it will choose one randomly from the input file 'Job Titles.txt'\n",
    "numberOfQuestions = 5 # The number of questions will be:\n",
    "                      #   - 1 Intro question of the style: tell me about yourself\n",
    "                      #   - <numberOfQuestions> randomly generated questions\n",
    "                      #   - <numberOfQuestions> followup questions to the previously generated questions\n",
    "                      # The total number of questions asked will be: <numberOfQuestions> x 2 + 1\n",
    "                      # For example, for numberOfQuestions = 5, the total number of questions asked will be 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if jobTitle == 'Random':\n",
    "    # Open the file in read mode\n",
    "    with open('Job Titles.txt', 'r') as f:\n",
    "        # Read all lines of the file into a list\n",
    "        jobs = f.readlines()\n",
    "\n",
    "    # Strip the '\\n' character from each element in the list\n",
    "    jobs = [job.strip() for job in jobs]\n",
    "\n",
    "    # Get the unique jobs from the input file\n",
    "    jobs = list(set(jobs))\n",
    "\n",
    "    # Get a random job title from the list.\n",
    "    jobIndex = random.randint(0,len(jobs)-1)\n",
    "    jobTitle = jobs[jobIndex]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.24.2)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.25.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.5.2)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.5.2.221213)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.24.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/carolinechiari/Library/Python/3.11/lib/python/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2.3->openai) (2022.7)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carolinechiari/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: simpleaudio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install azure-cognitiveservices-speech\n",
    "! pip3 install python-dotenv\n",
    "! pip3 install openai\n",
    "! pip3 install simpleaudio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "settings = {\n",
    "    'speechKey': os.environ.get('SPEECH_KEY'),\n",
    "    'region': os.environ.get('SPEECH_REGION'),\n",
    "    # Feel free to hardcode the language\n",
    "    'language': os.environ.get('SPEECH_LANGUAGE'),\n",
    "    'openAIKey': os.environ.get('OPENAI_KEY')\n",
    "}\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = settings['openAIKey']\n",
    "\n",
    "# Some sounds need to be generated over and over, like \"thank you\" or \"I didn't get that\".\n",
    "# There is no need to waste money re-generating them, so we will keep track of them here\n",
    "already_spoken = {}\n",
    "\n",
    "output_folder = f'./Output/{jobTitle}-{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}/'\n",
    "\n",
    "os.makedirs(output_folder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_openai(prompt, token=50,stop=\"\"):\n",
    "    \"\"\"\n",
    "    Generates completions for a given prompt using the OpenAI API.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt: The prompt for which completions are generated.\n",
    "    - token: The maximum number of tokens (words) in the generated completions.\n",
    "    - stop: A string that, if encountered in the generated completions, will cause the function to stop generating more completions.\n",
    "    \n",
    "    Returns:\n",
    "    A list of strings containing the generated completions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (not stop):\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.9,\n",
    "                max_tokens=token,\n",
    "                top_p=1,\n",
    "                presence_penalty = 1.5,\n",
    "                frequency_penalty = 1.5\n",
    "            )\n",
    "            lines = response.to_dict_recursive()['choices'][0]['text'].split(\"\\n\")\n",
    "            response = list(filter(lambda x: x != '', lines))\n",
    "            return response\n",
    "        else:\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.9,\n",
    "                max_tokens=token,\n",
    "                top_p=1,\n",
    "                presence_penalty = 1.5,\n",
    "                frequency_penalty = 1.5,\n",
    "                stop=[stop]\n",
    "            )\n",
    "            lines = response.to_dict_recursive()['choices'][0]['text'].split(\"\\n\")\n",
    "            response = list(filter(lambda x: x != '', lines))\n",
    "            return response\n",
    "    except Exception as e:\n",
    "        print(\"An exception of type\", type(e), \"occurred with the message:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a sound to indicate recording session is on or about to be stopped.\n",
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "\n",
    "def play_sound():\n",
    "    # set the frequency and duration\n",
    "    frequency = 440\n",
    "    duration = 0.1  # in seconds\n",
    "\n",
    "    # create a waveform\n",
    "    sample_rate = 44100\n",
    "    amplitude = 16000\n",
    "\n",
    "    waveform = np.sin(2 * np.pi * np.arange(sample_rate * duration) * frequency / sample_rate)\n",
    "    waveform = (waveform * amplitude).astype(np.int16)\n",
    "\n",
    "    # create a simpleaudio object\n",
    "    audio = sa.play_buffer(waveform, 1, 2, sample_rate)\n",
    "\n",
    "    # wait for the waveform to finish playing\n",
    "    audio.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "\n",
    "prop = False\n",
    "\n",
    "\n",
    "def Start_recording_answer():\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=settings['speechKey'], region=settings['region'])\n",
    "\n",
    "    speech_config.request_word_level_timestamps()\n",
    "    speech_config.set_property(\n",
    "        property_id=speechsdk.PropertyId.SpeechServiceResponse_OutputFormatOption, value=\"detailed\")\n",
    "\n",
    "    # Creates a speech recognizer using the default microphone (built-in).\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # initialize some variables\n",
    "    results = []\n",
    "    done = False\n",
    "    \n",
    "    # update the last time speech was detected. \n",
    "    def speech_detected():\n",
    "        nonlocal lastSpoken\n",
    "        lastSpoken = int(datetime.now().timestamp() * 1000)\n",
    "\n",
    "    # Event handler to add event to the result list\n",
    "    def handleResult(evt):\n",
    "        import json\n",
    "        nonlocal results\n",
    "        nonlocal lastSpoken\n",
    "        results.append(json.loads(evt.result.json))\n",
    "\n",
    "        # print the result (optional, otherwise it can run for a few minutes without output)\n",
    "        # print('RECOGNIZED: {}'.format(evt))\n",
    "        speech_detected()\n",
    "\n",
    "        # result object\n",
    "        res = {'text': evt.result.test, 'timestamp': evt.result.offset,\n",
    "               'duration': evt.result.duration, 'raw': evt.result}\n",
    "\n",
    "        if (evt.result.text != \"\"):\n",
    "            results.append(res)\n",
    "            \n",
    "            # print(evt.result)\n",
    "\n",
    "    # Event handler to check if the recognizer is done\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        # print('CLOSING on {}'.format(evt))\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer & displays the info/status\n",
    "    # Ref:https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.eventsignal?view=azure-python\n",
    "    speech_recognizer.recognizing.connect(lambda evt: speech_detected())\n",
    "    # speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(\n",
    "        lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(\n",
    "        lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(\n",
    "        lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(handleResult)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "    \n",
    "    # Start speech recognition\n",
    "    result_future = speech_recognizer.start_continuous_recognition_async()\n",
    "    result_future.get()\n",
    "\n",
    "    # Play sound to indicate that the recording session is on.\n",
    "    play_sound()\n",
    "\n",
    "    lastSpoken = int(datetime.now().timestamp() * 1000)\n",
    "\n",
    "    # Wait for speech recognition to complete\n",
    "    while not done:\n",
    "        time.sleep(1)\n",
    "        now = int(datetime.now().timestamp() * 1000)\n",
    "        inactivity = now - lastSpoken\n",
    "        # print(inactivity)\n",
    "        if (inactivity > 1000): # After 1 second of no speech detected, play a sound to indicate the recoding session could close.\n",
    "            play_sound()\n",
    "        if (inactivity > 3000): # Close the recoding session if no input is detected after 3s\n",
    "            print('Stopping async recognition.')\n",
    "            speech_recognizer.stop_continuous_recognition_async()\n",
    "            speak(\"Thank you!\")\n",
    "            while not done:\n",
    "                time.sleep(1)\n",
    "\n",
    "    output = \"\"\n",
    "    for res in results:\n",
    "        output += res['NBest'][0]['Display']\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "\n",
    "def speak(text,silent=False):\n",
    "\n",
    "    if text in already_spoken: # if the speech was already synthetized\n",
    "        if not silent:\n",
    "            play_obj = sa.WaveObject.from_wave_file(already_spoken[text]).play()\n",
    "            play_obj.wait_done()\n",
    "        return\n",
    "\n",
    "    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=settings['speechKey'], region=settings['region'])\n",
    "    # audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    file_name = f'{output_folder}/{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.wav'\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True,filename=file_name)\n",
    "\n",
    "    # The language of the voice that speaks.\n",
    "    speech_config.speech_synthesis_voice_name = 'en-US-JennyNeural'\n",
    "\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "        speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text(text) #.get()\n",
    "\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}]\".format(text))\n",
    "        if not silent:\n",
    "            play_obj = sa.WaveObject.from_wave_file(file_name).play()\n",
    "            play_obj.wait_done()\n",
    "        already_spoken[text]=file_name\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(\n",
    "            cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(\n",
    "                    cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n",
    "\n",
    "def speak_ssml(text):\n",
    "    # This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=settings['speechKey'], region=settings['region'])\n",
    "    # audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "    # The language of the voice that speaks.\n",
    "    speech_config.speech_synthesis_voice_name = 'en-US-JennyNeural'\n",
    "\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
    "        speech_config=speech_config, audio_config=None)\n",
    "\n",
    "    speech_synthesis_result = speech_synthesizer.speak_ssml(text) #.speak_text(text) #.get()\n",
    "\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}]\".format(text))\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(\n",
    "            cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(\n",
    "                    cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback(interviewer, interviewee):\n",
    "    prompt = \"\"\"\n",
    "write a paragraph to the interviewee describing what they did well in their response, and how they can improve:\n",
    "\n",
    "interviewer: {0}\n",
    "\n",
    "interviewee: {1}\n",
    "\"\"\".format(interviewer, interviewee)\n",
    "    # print(prompt)\n",
    "    res = complete_openai(prompt=prompt, token=int(4000-len(prompt.split())*1.75))\n",
    "    res = (\"\\n\".join(res))\n",
    "    return {'feedback':res,'score':get_score(interviewer=interviewer,interviewee=interviewee)}\n",
    "\n",
    "def get_score(interviewer, interviewee):\n",
    "    prompt = \"\"\"\n",
    "on a scale from 1 to 10 where 1 is the worst performance and 10 is the best, rater the interviewee's answer (only give me a number, no words):\n",
    "\n",
    "interviewer: {0}\n",
    "\n",
    "interviewee: {1}\n",
    "\"\"\".format(interviewer, interviewee)\n",
    "    # print(prompt)\n",
    "    res = complete_openai(prompt=prompt, token=int(4000-len(prompt.split())*1.75))\n",
    "    res = (\"\\n\".join(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_filter(item):\n",
    "    if item == '.':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = []\n",
    "askedQuestions = \"\"\n",
    "questions = complete_openai(prompt=f'Give me a list of {numberOfQuestions} questions an interviewer may ask for a {jobTitle} job interview. Provide them each on a new line with no dashes or numbers at the beginning',token=3000)\n",
    "questions = list(filter(openai_filter,questions))\n",
    "# wait = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [Good morning! Thank you for taking the time to speak with me today. I am very interested in learning more about your experience and qualifications as it relates to this Cloud Data Analyst role. To begin, can you tell me a bit about what motivated you to apply for this job?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=30299e8580fa430a9152e80966a94262)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=30299e8580fa430a9152e80966a94262)\n",
      "Speech synthesized for text [Thank you!]\n"
     ]
    }
   ],
   "source": [
    "intro = complete_openai(\n",
    "    prompt=\"Write the very first question for an interviewer interviewing an interviewee applying for a {0} job. Make sure to say a greeting, and also describe the role briefly.\".format(jobTitle), token=3000)\n",
    "introDialog = (\"\\n\".join(intro)).replace(\"Interviewer: \", \"\")\n",
    "speak(introDialog)\n",
    "askedQuestions+=\"{0}\\n\".format(introDialog)\n",
    "answer = Start_recording_answer()\n",
    "dialog += [{\n",
    "    'interviewer': introDialog,\n",
    "    'interviewee': answer[0]['DisplayText'],\n",
    "    'feedback': '',\n",
    "    'score': ''\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning! Thank you for taking the time to speak with me today. I am very interested in learning more about your experience and qualifications as it relates to this Cloud Data Analyst role. To begin, can you tell me a bit about what motivated you to apply for this job?\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "askedQuestions = \"\"\n",
    "askedQuestions+= \"{0}\\n\".format(introDialog)\n",
    "askedQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [1. What experience do you have in developing and implementing cloud data solutions? ]\n",
      "SESSION STARTED: SessionEventArgs(session_id=364d8bc6fb6e4509b426314ab336d131)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=364d8bc6fb6e4509b426314ab336d131)\n",
      "Speech synthesized for text [2. How experienced are you with generating insights from large datasets?  ]\n",
      "SESSION STARTED: SessionEventArgs(session_id=e70429e9a2fc486e8a7281e73c96af7f)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=e70429e9a2fc486e8a7281e73c96af7f)\n",
      "Speech synthesized for text [3. Are there any specific technologies or platforms that you feel comfortable working with when it comes to cloud data analysis? ]\n",
      "SESSION STARTED: SessionEventArgs(session_id=794862d044ae44a681ed8f02040fada7)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=794862d044ae44a681ed8f02040fada7)\n",
      "Speech synthesized for text [4. Describe a time where your analysis was used to make a successful business decision for an organization. ]\n",
      "SESSION STARTED: SessionEventArgs(session_id=5d2b343f06fe4b02918a1ec3b74e4348)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=5d2b343f06fe4b02918a1ec3b74e4348)\n",
      "Speech synthesized for text [5. What does best practice look like when analyzing, interpreting, and presenting complex datasets in the Cloud environment?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=283e3f283ea24cb19ac6cf702bee0faa)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=283e3f283ea24cb19ac6cf702bee0faa)\n",
      "Speech synthesized for text [What skills do you have as a data analyst, and how did those experience prepare you for this role in the cloud?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=ced5fd8010264e679292da3b86413235)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=ced5fd8010264e679292da3b86413235)\n",
      "Speech synthesized for text [Question: What specific tasks have you undertaken related to working with data in the cloud?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=fdc9073414654e7b91ae552c563b89fc)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=fdc9073414654e7b91ae552c563b89fc)\n",
      "Speech synthesized for text [Question: What techniques do you use when analyzing large datasets?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=3635272dd6a8443b8940e1df6c59eeee)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=3635272dd6a8443b8940e1df6c59eeee)\n",
      "Speech synthesized for text [What techniques have you used to generate insights from large datasets on Azure?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=b1f1f3d76e9c47f59e53ca6990e03c69)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=b1f1f3d76e9c47f59e53ca6990e03c69)\n",
      "Speech synthesized for text [Question: What experience do you have with ETL (Extract, Transform, and Load) processes for large datasets in the cloud?]\n",
      "SESSION STARTED: SessionEventArgs(session_id=a13792f48ea34c24ba2a59e1f03b1465)\n",
      "Stopping async recognition.\n",
      "SESSION STOPPED SessionEventArgs(session_id=a13792f48ea34c24ba2a59e1f03b1465)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, numberOfQuestions*2):\n",
    "    prompt = \"\"\"\n",
    "Provide the question the interviewer will ask to more effectively assess the candidate's experience and knowledge as it relates to a {2} role based on the following information (please only return the question):\n",
    "context: this is a job interview for a {2} role.\n",
    "Previously asked questions: {3}\n",
    "previous conversation:\n",
    "interviewer: {0}\n",
    "\n",
    "interviewee: {1}\n",
    "|\n",
    "\"\"\".format(dialog[len(dialog)-1]['interviewer'], dialog[len(dialog)-1]['interviewee'], jobTitle, askedQuestions, stop=\"|\")\n",
    "    interviewer = complete_openai(\n",
    "        prompt=prompt,\n",
    "        token=600\n",
    "    )\n",
    "    questions.append(interviewer[0])\n",
    "    # askedQuestions += \"{0}\\n\".format(interviewer[0])\n",
    "    speak(interviewer[0])\n",
    "    answer = \"\"\n",
    "    i = 0\n",
    "    while (len(answer) < 20):\n",
    "        if (i > 0):\n",
    "            speak(\"Sorry, I did not get that.\")\n",
    "        answer = (Start_recording_answer())[0]['DisplayText']\n",
    "        i += 1\n",
    "    dialog += [{\n",
    "        'interviewer': interviewer[0],\n",
    "        'interviewee': answer,\n",
    "        'feedback': \"\",\n",
    "        'score': \"\"\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [\n",
      "        For the question: Good morning! Thank you for taking the time to speak with me today. I am very interested in learning more about your experience and qualifications as it relates to this Cloud Data Analyst role. To begin, can you tell me a bit about what motivated you to apply for this job?\n",
      "        The feedback is: You did a great job of expressing your motivation for applying to this role. You clearly demonstrated that you have experience working in the data analyst space and with cloud data, which will likely be beneficial when it comes time to apply your knowledge on the job. Perhaps next time, you can use concrete examples to further demonstrate how these experiences could come into play as it relates specifically to this Cloud Data Analyst position.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 8 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: 1. What experience do you have in developing and implementing cloud data solutions? \n",
      "        The feedback is: You did a great job of highlighting your cloud data experience in this response. You demonstrated knowledge and explained the different areas you have been involved with such as data warehousing, helping scientists with their workflows and transferring data around. To further strengthen your answer, you could also provide concrete examples or case studies if possible to showcase how you leveraged digital technologies in particular projects that had successful outcomes.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 9 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: 2. How experienced are you with generating insights from large datasets?  \n",
      "        The feedback is: You did a great job highlighting your range of experiences in data analysis, from the research context at CERN to mainstream professional settings. Your enthusiasm for working with large datasets was evident and that's very important. You could consider providing some more concrete details about the projects you've been involved with and how they informed decisions or led to success stories; this would help demonstrate both your level of understanding and experience when it comes to extracting insights from large datasets.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 8 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: 3. Are there any specific technologies or platforms that you feel comfortable working with when it comes to cloud data analysis? \n",
      "        The feedback is: You did a great job of expressing your knowledge and ability to learn new technologies. You clearly have experience with Azure, which is impressive; however, you could benefit from mentioning any specific software tools related to cloud data analysis that you are comfortable working with. In addition, it would be beneficial for you to talk about other platforms or languages outside of Azure in order demonstrate an even broader understanding of the field.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 9 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: 4. Describe a time where your analysis was used to make a successful business decision for an organization. \n",
      "        The feedback is: You gave a clear example of how your analysis was used to make successful decisions in the IT field. Your explanation revealed that you have expertise in leveraging data and making well-informed business choices. To improve, it would be helpful to provide some facts and results from past projects so that interviewers can gain a better understanding of how your analysis positively impacted an organization's bottom line.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 7 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: 5. What does best practice look like when analyzing, interpreting, and presenting complex datasets in the Cloud environment?\n",
      "        The feedback is: You did well in your response by recognizing that best practices vary depending on the particular situation and dataset. To further improve, you could offer examples of how companies from different industries might approach analyzing and presenting their data differently or suggest ways that teams can collaborate effectively to tackle complex datasets in a Cloud environment.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 8 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: What skills do you have as a data analyst, and how did those experience prepare you for this role in the cloud?\n",
      "        The feedback is: You did a great job expressing your abilities as a data analyst! You've clearly done work with big data and programming, which makes you an ideal candidate for this role in the cloud. To make sure that employers are confident in your skillset, it may be beneficial to offer more details on any specific projects or tasks related to cloud computing that you have worked on or experiences using tools such as AWS and other different platforms.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 9 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: Question: What specific tasks have you undertaken related to working with data in the cloud?\n",
      "        The feedback is: You did a great job in describing your experience working with data in the cloud. You clearly have an understanding of cost analysis, machine learning and Azure subscriptions which was very impressive. Moving forward, focus on emphasizing how you can use this knowledge to solve problems or come up with solutions that could benefit the company. Doing so will really showcase your ability to think critically when presented with complex tasks related to working with data in the cloud.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 9 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: Question: What techniques do you use when analyzing large datasets?\n",
      "        The feedback is: You did very well in responding to this question by discussing the various machine learning techniques that you use. You also gave an example of how different types of data require different approaches and strategies, which is a great indication of your knowledge on the subject. To further improve your response, it might be beneficial to give more concrete examples or descriptions around specific technologies you have used before when analyzing large datasets. This would help illustrate both your understanding and experience with such tasks.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 9 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: What techniques have you used to generate insights from large datasets on Azure?\n",
      "        The feedback is: You did a great job of articulating the different techniques you use on Azure and particularly how they are applicable in unique situations. You should also try to elaborate further by giving some concrete examples for each technique, and how it helped generate insights from large datasets.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 7 out of 10.  \n",
      "]\n",
      "Speech synthesized for text [\n",
      "        For the question: Question: What experience do you have with ETL (Extract, Transform, and Load) processes for large datasets in the cloud?\n",
      "        The feedback is: You did well in your response by providing relevant information that directly answered the question. However, to provide a more complete answer you could also explain any transformations and loading processes you have experience with. This would give additional insight into your expertise on ETL processes for large datasets in the cloud.\n",
      "        \n",
      "        Overall, I would rate your performance for this question a 7 out of 10.  \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "speak(\"Here is your feedback:\",silent=True)\n",
    "for interaction in dialog:\n",
    "    feedback = get_feedback(\n",
    "        interaction['interviewer'], interaction['interviewee'])\n",
    "    interaction['feedback'] = feedback['feedback']\n",
    "    interaction['score'] = feedback['score']\n",
    "    speak(\"\"\"\n",
    "        For the question: {0}\n",
    "        The feedback is: {1}\n",
    "        \n",
    "        Overall, I would rate your performance for this question a {2} out of 10.  \n",
    "\"\"\".format(interaction['interviewer'], interaction['feedback'],interaction['score']))\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = \"\"\n",
    "for interaction in dialog:\n",
    "    output+=\"\"\"\n",
    "Question:\n",
    "{0}\n",
    "\n",
    "Feedback:\n",
    "{1}\n",
    "\n",
    "Score:\n",
    "{2}/10\n",
    "-------------------------------------\n",
    "\"\"\".format(interaction['interviewer'],interaction['feedback'],interaction['score'])\n",
    "\n",
    "# Open a file in write mode\n",
    "with open(f'{output_folder}/transcript-feedback.txt', \"w\") as f:\n",
    "    # Write the string to the file\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What experience do you have in developing and implementing cloud data solutions? \n",
      "1. What experience do you have in developing and implementing cloud data solutions? \n",
      "---\n",
      "2. How experienced are you with generating insights from large datasets?  \n",
      "2. How experienced are you with generating insights from large datasets?  \n",
      "---\n",
      "3. Are there any specific technologies or platforms that you feel comfortable working with when it comes to cloud data analysis? \n",
      "3. Are there any specific technologies or platforms that you feel comfortable working with when it comes to cloud data analysis? \n",
      "---\n",
      "4. Describe a time where your analysis was used to make a successful business decision for an organization. \n",
      "4. Describe a time where your analysis was used to make a successful business decision for an organization. \n",
      "---\n",
      "5. What does best practice look like when analyzing, interpreting, and presenting complex datasets in the Cloud environment?\n",
      "5. What does best practice look like when analyzing, interpreting, and presenting complex datasets in the Cloud environment?\n",
      "---\n",
      "What skills do you have as a data analyst, and how did those experience prepare you for this role in the cloud?\n",
      "What skills do you have as a data analyst, and how did those experience prepare you for this role in the cloud?\n",
      "---\n",
      "Question: What specific tasks have you undertaken related to working with data in the cloud?\n",
      "Question: What specific tasks have you undertaken related to working with data in the cloud?\n",
      "---\n",
      "Question: What techniques do you use when analyzing large datasets?\n",
      "Question: What techniques do you use when analyzing large datasets?\n",
      "---\n",
      "What techniques have you used to generate insights from large datasets on Azure?\n",
      "What techniques have you used to generate insights from large datasets on Azure?\n",
      "---\n",
      "Question: What experience do you have with ETL (Extract, Transform, and Load) processes for large datasets in the cloud?\n",
      "Question: What experience do you have with ETL (Extract, Transform, and Load) processes for large datasets in the cloud?\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(dialog)):\n",
    "    print(dialog[i]['interviewer'])\n",
    "    print(questions[i-1])\n",
    "    # dialog[i]['interviewer'] = questions[i-1]\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak(\"Here is your feedback:\")\n",
    "# speak_ssml(\"\"\"\n",
    "# <speak\n",
    "#     version=\"1.0\"\n",
    "#     xmlns=\"https://www.w3.org/2001/10/synthesis\"\n",
    "#     xmlns:mstts=\"https://www.w3.org/2001/mstts\"\n",
    "#     xml:lang=\"en-US\"\n",
    "#     >\n",
    "#   <voice name=\"en-US-JennyNeural\">\n",
    "#     <express-as style=\"calm\">\n",
    "#         For the question:\n",
    "#     </express-as>\n",
    "#     <mstts:express-as role=\"YoungAdultMale\" style=\"calm\">\n",
    "#         Good morning! Thank you for taking the time to meet with us today. We are currently looking to fill a role as Cloud Engineer, which will involve designing and building our company’s cloud-based infrastructure. To start off this interview, can you tell me about your experience working on cloud systems?\n",
    "#     </mstts:express-as>\n",
    "#     <mstts:express-as role=\"YoungAdultFemale\" style=\"calm\">\n",
    "#         The feedback is:\n",
    "#     </mstts:express-as>\n",
    "#     <mstts:express-as role=\"YoungAdultMale\" style=\"calm\">\n",
    "#         Your response was strong and detailed; you gave us clear examples of your experience working on cloud systems. You mentioned that you have been doing this for two years, which is important context to show the scope of knowledge and expertise. In the future, it would be great to provide an example or two about a project in which you utilized these skills so we can better understand how involved and successful you are at utilizing the cloud.\n",
    "#     </mstts:express-as>\n",
    "#     <mstts:express-as role=\"YoungAdultFemale\" style=\"calm\">\n",
    "#         Overall, I would rate your performance for this question a 9 out of 10.\n",
    "#     </mstts:express-as>\n",
    "#   </voice>\n",
    "# </speak> \n",
    "# \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
